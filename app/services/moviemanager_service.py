import os
import json
import boto3
from typing import List, Dict
from app.services.transcribe_service import transcribe_video
from app.services.scene_service import get_video_scenes
import asyncio

def create_claude_prompt_with_context(utterances: List[Dict], scene_images: List[Dict], previous_summaries: List[str] = None) -> str:
    """
    ì´ì „ ìš”ì•½ë“¤ì„ í¬í•¨í•˜ì—¬ Claude í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    conversation = "\n".join([
        f"[{utterance['speaker']}] {utterance['text']}"
        for utterance in utterances
    ])
    
    scene_times = "\n".join([
        f"Scene {i+1}: start_time={scene['start_time']}"
        for i, scene in enumerate(scene_images)
    ])
    
    # ì´ì „ ìš”ì•½ë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¶”ê°€
    context = ""
    if previous_summaries:
        context = "\n\n[ì´ì „ ì˜ìƒë“¤ì˜ ì¤„ê±°ë¦¬]\n" + "\n\n".join([
            f"ì˜ìƒ {i+1}: {summary}" 
            for i, summary in enumerate(previous_summaries)
        ]) + "\n\n"
    
    prompt = f"""ë‹¤ìŒì€ ì—°ì†ëœ ë¹„ë””ì˜¤ ì‹œë¦¬ì¦ˆì˜ ì¼ë¶€ì…ë‹ˆë‹¤.{context}[í˜„ì¬ ì˜ìƒì˜ ëŒ€í™” ë‚´ìš©]\n{conversation}\n\n[í˜„ì¬ ì˜ìƒì˜ ì¥ë©´ë³„ ì‹œì‘ ì‹œê°]\n{scene_times}\n\nì´ì „ ì˜ìƒë“¤ì˜ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ í˜„ì¬ ì˜ìƒì— ëŒ€í•´:\n1. ê° ì¥ë©´ì´ ë³´ì—¬ì£¼ëŠ” ìƒí™©ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”\n2. ëŒ€í™” ë‚´ìš©ê³¼ ì—°ê´€ì§€ì–´ ì„¤ëª…í•´ì£¼ì„¸ìš”\n3. ì´ì „ ì˜ìƒë“¤ê³¼ì˜ ì—°ê²°ì ì´ë‚˜ ìŠ¤í† ë¦¬ ì§„í–‰ì„ ë¶„ì„í•´ì£¼ì„¸ìš”\n\ní˜„ì¬ ì˜ìƒì˜ ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”."""
    
    return prompt

async def get_bedrock_response_with_context(utterances: List[Dict], scene_images: List[Dict], previous_summaries: List[str] = None) -> str:
    """
    ì´ì „ ìš”ì•½ë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬í•¨í•˜ì—¬ Bedrock Claude ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    bedrock = boto3.client(
        service_name='bedrock-runtime',
        region_name=os.getenv("AWS_DEFAULT_REGION")
    )
    model_id = os.getenv("BEDROCK_MODEL_ID")

    # í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ìƒì„± (ì´ì „ ìš”ì•½ í¬í•¨)
    text_prompt = create_claude_prompt_with_context(utterances, scene_images, previous_summaries)
    
    # ë””ë²„ê¹…: í”„ë¡¬í”„íŠ¸ ì¶œë ¥
    print("=" * 80)
    print("ğŸ“ PROMPT INPUT:")
    print("=" * 80)
    print(text_prompt)
    print("=" * 80)

    # ë©€í‹°ëª¨ë‹¬ ë©”ì‹œì§€ êµ¬ì„±
    content = []
    for i, scene in enumerate(scene_images):
        content.append({
            "type": "image",
            "source": {
                "type": "base64",
                "media_type": "image/jpeg",
                "data": scene["image"]
            }
        })
    content.append({
        "type": "text",
        "text": text_prompt
    })

    request_body = {
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 4096,
        "messages": [
            {
                "role": "user",
                "content": content
            }
        ]
    }
    
    response = bedrock.invoke_model(
        modelId=model_id,
        body=json.dumps(request_body)
    )
    response_body = json.loads(response['body'].read())
    claude_response = response_body['content'][0]['text']
    
    # ë””ë²„ê¹…: ëª¨ë¸ ë‹µë³€ ì¶œë ¥
    print("ğŸ¤– CLAUDE RESPONSE:")
    print("=" * 80)
    print(claude_response)
    print("=" * 80)
    
    return claude_response

async def create_final_summary(video_summaries: List[str]) -> str:
    """
    ëª¨ë“  ë¹„ë””ì˜¤ ìš”ì•½ì„ ì¢…í•©í•˜ì—¬ ìµœì¢… ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    bedrock = boto3.client(
        service_name='bedrock-runtime',
        region_name=os.getenv("AWS_DEFAULT_REGION") or "us-east-1"
    )
    model_id = os.getenv("BEDROCK_MODEL_ID") or "anthropic.claude-3-sonnet-20240229-v1:0"

    # ëª¨ë“  ìš”ì•½ì„ í•˜ë‚˜ë¡œ í•©ì¹¨
    all_summaries = "\n\n".join([
        f"ì˜ìƒ {i+1}:\n{summary}" 
        for i, summary in enumerate(video_summaries)
    ])
    
    prompt = f"""ë‹¤ìŒì€ ì—°ì†ëœ ë¹„ë””ì˜¤ ì‹œë¦¬ì¦ˆì˜ ê° ì˜ìƒë³„ ìš”ì•½ì…ë‹ˆë‹¤:\n\n{all_summaries}\n\nìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ:\n1. ì „ì²´ ìŠ¤í† ë¦¬ì˜ íë¦„ì„ ì •ë¦¬í•´ì£¼ì„¸ìš”\n2. ì£¼ìš” ë“±ì¥ì¸ë¬¼ê³¼ ê·¸ë“¤ì˜ ê´€ê³„ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”\n3. í•µì‹¬ ì‚¬ê±´ë“¤ê³¼ ê°ˆë“± êµ¬ì¡°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”\n4. ì „ì²´ ì˜ìƒ ì‹œë¦¬ì¦ˆì˜ ì£¼ì œì™€ ë©”ì‹œì§€ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”\n\nìµœì¢…ì ìœ¼ë¡œ ì „ì²´ ì˜ìƒ ì‹œë¦¬ì¦ˆì— ëŒ€í•œ ì¢…í•©ì ì¸ ìš”ì•½ì„ ì œê³µí•´ì£¼ì„¸ìš”."""

    # ë””ë²„ê¹…: ìµœì¢… ìš”ì•½ í”„ë¡¬í”„íŠ¸ ì¶œë ¥
    print("=" * 80)
    print("ğŸ¬ FINAL SUMMARY PROMPT INPUT:")
    print("=" * 80)
    print(prompt)
    print("=" * 80)

    request_body = {
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 4096,
        "messages": [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": prompt
                    }
                ]
            }
        ]
    }
    
    response = bedrock.invoke_model(
        modelId=model_id,
        body=json.dumps(request_body)
    )
    response_body = json.loads(response['body'].read())
    final_response = response_body['content'][0]['text']
    
    # ë””ë²„ê¹…: ìµœì¢… ìš”ì•½ ë‹µë³€ ì¶œë ¥
    print("ğŸ­ FINAL SUMMARY RESPONSE:")
    print("=" * 80)
    print(final_response)
    print("=" * 80)
    
    return final_response

async def process_multiple_videos(s3_video_uris: List[str], language_code: str = "ko-KR", threshold: float = 30.0) -> Dict:
    """
    ì—¬ëŸ¬ ë¹„ë””ì˜¤ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ê°ê°ì˜ ìš”ì•½ê³¼ ìµœì¢… ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        video_summaries = []
        previous_summaries = []
        
        print(f"ğŸ¥ ì´ {len(s3_video_uris)}ê°œì˜ ë¹„ë””ì˜¤ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        print("=" * 80)
        
        for i, video_uri in enumerate(s3_video_uris):
            print(f"ğŸ¬ [{i+1}/{len(s3_video_uris)}] ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œì‘: {video_uri}")
            
            # transcribeì™€ scene ë³‘ë ¬ ì²˜ë¦¬
            transcribe_task = asyncio.to_thread(transcribe_video, video_uri, language_code)
            scene_task = asyncio.to_thread(get_video_scenes, video_uri, threshold)
            utterances, scenes = await asyncio.gather(transcribe_task, scene_task)
            
            print(f"âœ… STT ê²°ê³¼: {len(utterances)}ê°œì˜ ë°œí™”")
            print(f"âœ… ì¥ë©´ ê°ì§€: {len(scenes)}ê°œì˜ ì¥ë©´")
            
            # sceneì˜ base64 ì´ë¯¸ì§€ì™€ start_time ì¶”ì¶œ
            scene_images = [
                {"start_time": scene["start_time"], "image": scene["frame_image"]}
                for scene in scenes
            ]
            
            # ì´ì „ ìš”ì•½ë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬í•¨í•˜ì—¬ í˜„ì¬ ë¹„ë””ì˜¤ ìš”ì•½ ìƒì„±
            summary = await get_bedrock_response_with_context(utterances, scene_images, previous_summaries)
            
            video_summaries.append({
                "video_uri": video_uri,
                "summary": summary,
                "order": i + 1
            })
            
            # ë‹¤ìŒ ë¹„ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì´ì „ ìš”ì•½ì— ì¶”ê°€
            previous_summaries.append(summary)
            
            print(f"âœ… [{i+1}/{len(s3_video_uris)}] ë¹„ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ")
            print("=" * 80)
        
        print("ğŸ­ ìµœì¢… ì¢…í•© ìš”ì•½ ìƒì„± ì¤‘...")
        # ìµœì¢… ì¢…í•© ìš”ì•½ ìƒì„±
        final_summary = await create_final_summary([vs["summary"] for vs in video_summaries])
        
        print("ğŸ‰ ëª¨ë“  ë¹„ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ!")
        print("=" * 80)
        
        return {
            "video_summaries": video_summaries,
            "final_summary": final_summary
        }
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise RuntimeError(f"ë‹¤ì¤‘ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}") 